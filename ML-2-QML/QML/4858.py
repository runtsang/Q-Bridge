"""
Hybrid quantum autoencoder leveraging TorchQuantum for encoding and a
classical decoder.  The quantum encoder implements a fixed ansatz that
acts as a quantum kernel; the latent vector is extracted from the
measurement of the final state.  The decoder is a dense neural net
mirroring the classical counterpart.

This module is fully compatible with the classical version, but the
latent representation is generated by a quantum circuit, providing
a natural bridge to quantum kernel methods and quanvolution
experiments.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Tuple

import torch
import torchquantum as tq
from torchquantum.functional import func_name_dict


# --------------------------------------------------------------------------- #
# 1. Quantum kernel ansatz (fixed set of Ry gates)
# --------------------------------------------------------------------------- #
class QuantumKernelAnsatz(tq.QuantumModule):
    """
    Encodes classical data into a multi‑qubit state by applying a
    sequence of single‑qubit Ry rotations.  The same sequence is applied
    with opposite signs to compute a kernel between two inputs.
    """

    def __init__(self, n_qubits: int = 4) -> None:
        super().__init__()
        self.n_qubits = n_qubits
        self.ansatz = tq.GeneralEncoder(
            [
                {"input_idx": [i], "func": "ry", "wires": [i]}
                for i in range(n_qubits)
            ]
        )

    @tq.static_support
    def forward(self, q_device: tq.QuantumDevice, x: torch.Tensor, y: torch.Tensor) -> None:
        """Apply the encoding to both x and y, accumulating the inner product."""
        q_device.reset_states(x.shape[0])
        self.ansatz(q_device, x)
        # Reverse sign for y (computes overlap with conjugate)
        self.ansatz(q_device, -y)


class QuantumKernel(tq.QuantumModule):
    """
    Quantum kernel that returns the absolute value of the first amplitude
    of the state after applying the ansatz to two inputs.
    """

    def __init__(self, n_qubits: int = 4) -> None:
        super().__init__()
        self.n_qubits = n_qubits
        self.q_device = tq.QuantumDevice(n_wires=self.n_qubits)
        self.kernel_ansatz = QuantumKernelAnsatz(n_qubits)

    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
        x = x.reshape(1, -1)
        y = y.reshape(1, -1)
        self.kernel_ansatz(self.q_device, x, y)
        # The first amplitude corresponds to the overlap
        return torch.abs(self.q_device.states.view(-1)[0])


def kernel_matrix(a: list[torch.Tensor], b: list[torch.Tensor], n_qubits: int = 4) -> torch.Tensor:
    """Compute Gram matrix using the quantum kernel."""
    kernel = QuantumKernel(n_qubits)
    return torch.stack(
        [torch.stack([kernel(x, y) for y in b]) for x in a]
    )


# --------------------------------------------------------------------------- #
# 2. Hybrid quantum autoencoder configuration
# --------------------------------------------------------------------------- #
@dataclass
class HybridQuantumAutoencoderConfig:
    input_dim: int
    latent_dim: int = 32
    hidden_dims: Tuple[int, int] = (128, 64)
    dropout: float = 0.1
    n_qubits: int = 4  # number of qubits used in the kernel ansatz


# --------------------------------------------------------------------------- #
# 3. Hybrid quantum autoencoder network
# --------------------------------------------------------------------------- #
class HybridQuantumAutoencoderNet(torch.nn.Module):
    """
    Quantum encoder + classical dense decoder.
    The encoder produces a latent vector by measuring the quantum state
    after applying the kernel ansatz to the input.  The decoder mirrors
    the classical dense decoder of the hybrid autoencoder.
    """

    def __init__(self, config: HybridQuantumAutoencoderConfig) -> None:
        super().__init__()
        self.config = config

        # Quantum kernel device
        self.kernel = QuantumKernel(config.n_qubits)

        # Classical decoder
        decoder_layers = []
        in_dim = config.latent_dim
        for hidden in reversed(config.hidden_dims):
            decoder_layers.append(torch.nn.Linear(in_dim, hidden))
            decoder_layers.append(torch.nn.ReLU())
            if config.dropout > 0.0:
                decoder_layers.append(torch.nn.Dropout(config.dropout))
            in_dim = hidden
        decoder_layers.append(torch.nn.Linear(in_dim, config.input_dim))
        self.decoder = torch.nn.Sequential(*decoder_layers)

    def encode(self, inputs: torch.Tensor) -> torch.Tensor:
        """
        Encode inputs into a latent vector via quantum kernel measurement.
        Each sample produces a scalar (overlap), which is stacked into a
        vector of size (B, latent_dim).  For simplicity we repeat the
        same measurement latent_dim times.
        """
        B = inputs.shape[0]
        latent = torch.empty(B, self.config.latent_dim, device=inputs.device)
        for i in range(self.config.latent_dim):
            latent[:, i] = self.kernel(inputs, inputs).unsqueeze(1)
        return latent

    def decode(self, latents: torch.Tensor) -> torch.Tensor:
        return self.decoder(latents)

    def forward(self, inputs: torch.Tensor) -> torch.Tensor:
        return self.decode(self.encode(inputs))


def HybridQuantumAutoencoder(
    input_dim: int,
    *,
    latent_dim: int = 32,
    hidden_dims: Tuple[int, int] = (128, 64),
    dropout: float = 0.1,
    n_qubits: int = 4,
) -> HybridQuantumAutoencoderNet:
    """Factory that creates a fully‑configured hybrid quantum autoencoder."""
    config = HybridQuantumAutoencoderConfig(
        input_dim=input_dim,
        latent_dim=latent_dim,
        hidden_dims=hidden_dims,
        dropout=dropout,
        n_qubits=n_qubits,
    )
    return HybridQuantumAutoencoderNet(config)


# --------------------------------------------------------------------------- #
# 4. Training helper
# --------------------------------------------------------------------------- #
def train_hybrid_qautoencoder(
    model: HybridQuantumAutoencoderNet,
    data: torch.Tensor,
    *,
    epochs: int = 100,
    batch_size: int = 64,
    lr: float = 1e-3,
    weight_decay: float = 0.0,
    device: torch.device | None = None,
) -> list[float]:
    """
    Training loop for the hybrid quantum autoencoder.  Uses MSE loss
    between reconstructions and inputs.  The encoder is quantum, the
    decoder is classical.
    """
    device = device or torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    dataset = torch.utils.data.TensorDataset(_as_tensor(data))
    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)

    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    loss_fn = torch.nn.MSELoss()
    history: list[float] = []

    for _ in range(epochs):
        epoch_loss = 0.0
        for (batch,) in loader:
            batch = batch.to(device)
            optimizer.zero_grad(set_to_none=True)
            reconstruction = model(batch)
            loss = loss_fn(reconstruction, batch)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item() * batch.size(0)
        epoch_loss /= len(dataset)
        history.append(epoch_loss)
    return history


def _as_tensor(data: torch.Tensor | list | tuple) -> torch.Tensor:
    """Utility: ensure input is a float32 tensor on the CPU."""
    if isinstance(data, torch.Tensor):
        tensor = data
    else:
        tensor = torch.as_tensor(data, dtype=torch.float32)
    if tensor.dtype!= torch.float32:
        tensor = tensor.to(dtype=torch.float32)
    return tensor


__all__ = [
    "HybridQuantumAutoencoder",
    "HybridQuantumAutoencoderNet",
    "HybridQuantumAutoencoderConfig",
    "train_hybrid_qautoencoder",
]
