"""HybridBinaryClassifier â€“ Qiskit implementation.

This module mirrors the classical version but replaces the dense
classifier with a variational quantum circuit whose topology is
generated by the same `build_classifier_circuit` function used
in the classical module.  The circuit is wrapped by
`qiskit_machine_learning.neural_networks.EstimatorQNN`, which
provides a differentiable interface compatible with PyTorch.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import List

from qiskit import QuantumCircuit, transpile, assemble
from qiskit.circuit import ParameterVector
from qiskit.quantum_info import SparsePauliOp
from qiskit_machine_learning.neural_networks import EstimatorQNN
from qiskit.primitives import Sampler
from qiskit_aer import AerSimulator

__all__ = ["HybridBinaryClassifier"]


def build_classifier_circuit_qiskit(num_qubits: int, depth: int) -> (
    QuantumCircuit,
    List[ParameterVector],
    List[ParameterVector],
    List[SparsePauliOp],
):
    """Construct a layered ansatz with explicit encoding and
    variational parameters.  The interface matches the classical
    `build_classifier_circuit` so the two models have identical
    topology.
    """
    encoding = ParameterVector("x", num_qubits)
    weights = ParameterVector("theta", num_qubits * depth)

    qc = QuantumCircuit(num_qubits)
    for param, qubit in zip(encoding, range(num_qubits)):
        qc.rx(param, qubit)

    idx = 0
    for _ in range(depth):
        for qubit in range(num_qubits):
            qc.ry(weights[idx], qubit)
            idx += 1
        for qubit in range(num_qubits - 1):
            qc.cz(qubit, qubit + 1)

    observables = [
        SparsePauliOp("I" * i + "Z" + "I" * (num_qubits - i - 1))
        for i in range(num_qubits)
    ]
    return qc, list(encoding), list(weights), observables


class QuantumHybridLayer(nn.Module):
    """Differentiable wrapper around a Qiskit EstimatorQNN."""

    def __init__(
        self,
        num_qubits: int,
        depth: int,
        shift: float = 0.0,
        shots: int = 100,
        backend=None,
    ) -> None:
        super().__init__()
        self.shift = shift

        qc, enc, weights, obs = build_classifier_circuit_qiskit(num_qubits, depth)

        if backend is None:
            backend = AerSimulator()
        sampler = Sampler(backend)

        # EstimatorQNN expects a parameter list: input + weight
        estimator = EstimatorQNN(
            circuit=qc,
            observables=obs,
            input_params=enc,
            weight_params=weights,
            estimator=sampler,
        )
        self.estimator_qnn = estimator

        self.num_qubits = num_qubits

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Flatten and ensure correct shape
        flat = x.view(x.size(0), -1)
        # EstimatorQNN expects a numpy array of shape (batch, params)
        params = flat.cpu().numpy()
        # Run the quantum circuit
        results = self.estimator_qnn.predict(params)
        # Convert back to torch
        out = torch.tensor(results, dtype=torch.float32, device=x.device)
        return out


class HybridBinaryClassifier(nn.Module):
    """CNN backbone followed by a variational quantum classifier head."""

    def __init__(
        self,
        num_features: int = 32,
        depth: int = 4,
        shift: float = 0.0,
        shots: int = 100,
        backend=None,
    ) -> None:
        super().__init__()

        # Convolutional backbone identical to classical version
        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=2, padding=1)
        self.conv2 = nn.Conv2d(6, 15, kernel_size=3, stride=2, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=1)
        self.drop1 = nn.Dropout2d(p=0.2)
        self.drop2 = nn.Dropout2d(p=0.5)

        dummy_input = torch.zeros(1, 3, 32, 32)
        dummy_out = self._forward_conv(dummy_input)
        flat_size = dummy_out.shape[1]

        # Dense reduction before quantum head
        self.fc_reduce = nn.Linear(flat_size, num_features)
        self.bn_reduce = nn.BatchNorm1d(num_features)

        # Quantum head
        self.quantum_head = QuantumHybridLayer(
            num_qubits=num_features,
            depth=depth,
            shift=shift,
            shots=shots,
            backend=backend,
        )

        self.shift = shift

    def _forward_conv(self, x: torch.Tensor) -> torch.Tensor:
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = self.drop1(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = self.drop1(x)
        return torch.flatten(x, 1)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self._forward_conv(x)
        x = self.bn_reduce(self.fc_reduce(x))
        x = self.quantum_head(x)
        # Apply shift and sigmoid to match classical head
        probs = torch.sigmoid(x + self.shift)
        return torch.cat((probs, 1 - probs), dim=-1)
