import torch
import torch.nn as nn
import numpy as np
from qml_selfattention import QuantumSelfAttention

class SelfAttention(nn.Module):
    """Hybrid multi‑head self‑attention module.

    Parameters
    ----------
    embed_dim : int
        Dimensionality of the input embeddings.
    seq_len : int
        Length of the input sequence (also the number of qubits used in the quantum circuit).
    num_heads : int, default 4
        Number of attention heads.
    use_quantum : bool, default False
        If True, attention weights are generated by a variational quantum circuit.
    quantum_shots : int, default 1024
        Number of shots for the quantum simulator.
    """

    def __init__(
        self,
        embed_dim: int,
        seq_len: int,
        num_heads: int = 4,
        use_quantum: bool = False,
        quantum_shots: int = 1024,
    ):
        super().__init__()
        assert embed_dim % num_heads == 0, "embed_dim must be divisible by num_heads"
        self.embed_dim = embed_dim
        self.seq_len = seq_len
        self.num_heads = num_heads
        self.head_dim = embed_dim // num_heads
        self.use_quantum = use_quantum

        # Linear projections
        self.q_lin = nn.Linear(embed_dim, embed_dim)
        self.k_lin = nn.Linear(embed_dim, embed_dim)
        self.v_lin = nn.Linear(embed_dim, embed_dim)
        self.out_lin = nn.Linear(embed_dim, embed_dim)

        if self.use_quantum:
            self.quantum_attention = QuantumSelfAttention(
                n_qubits=seq_len, shots=quantum_shots
            )

    def forward(
        self,
        x: torch.Tensor,
        rotation_params: np.ndarray,
        entangle_params: np.ndarray,
    ) -> torch.Tensor:
        """
        Parameters
        ----------
        x : torch.Tensor
            Input tensor of shape (batch, seq_len, embed_dim).
        rotation_params : np.ndarray
            Array of shape (num_heads, seq_len * 3) containing rotation angles
            for the quantum circuit (rx, ry, rz for each qubit).
        entangle_params : np.ndarray
            Array of shape (num_heads, seq_len - 1) containing entanglement angles.
        """
        batch, seq_len, _ = x.shape
        assert seq_len == self.seq_len, "Sequence length mismatch."

        # Linear projections
        q = self.q_lin(x).view(batch, seq_len, self.num_heads, self.head_dim)
        k = self.k_lin(x).view(batch, seq_len, self.num_heads, self.head_dim)
        v = self.v_lin(x).view(batch, seq_len, self.num_heads, self.head_dim)

        # Attention scores
        scores = torch.einsum("bshd,bshd->bsh", q, k) / np.sqrt(self.head_dim)

        if self.use_quantum:
            # Quantum-derived attention weights
            attn_weights = []
            for h in range(self.num_heads):
                rot = rotation_params[h]
                ent = entangle_params[h]
                probs = self.quantum_attention.run(rot, ent)  # shape (seq_len,)
                attn_weights.append(probs)
            attn_weights = torch.tensor(attn_weights, dtype=torch.float32, device=x.device)
            # Shape: (num_heads, seq_len) -> (1, num_heads, seq_len)
            attn_weights = attn_weights.unsqueeze(0).expand(batch, -1, -1)
        else:
            attn_weights = torch.softmax(scores, dim=1)

        # Weighted sum of values
        out = torch.einsum("bsh,bshd->bshd", attn_weights, v)
        out = out.contiguous().view(batch, seq_len, self.embed_dim)
        out = self.out_lin(out)
        return out

__all__ = ["SelfAttention"]
